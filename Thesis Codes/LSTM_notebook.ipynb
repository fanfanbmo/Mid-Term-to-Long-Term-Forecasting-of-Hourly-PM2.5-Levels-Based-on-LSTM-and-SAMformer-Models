{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('AQI.csv')\n",
    "data['time'] = pd.to_datetime(data['time'])\n",
    "data.set_index('time')\n",
    "time = data['time']\n",
    "\n",
    "fold = 3\n",
    "# Split into training, validation, and test sets according to time\n",
    "# fold 1\n",
    "if fold == 1:\n",
    "    train = data[(time >= '2018-01-01 00:00:00') & (time <= '2018-12-31 23:00:00')]\n",
    "    validation = data[(time >= '2019-01-01 00:00:00') & (time <= '2019-12-31 23:00:00')]\n",
    "# fold 2\n",
    "if fold == 2:\n",
    "    train = data[(time >= '2018-01-01 00:00:00') & (time <= '2019-12-31 23:00:00')]\n",
    "    validation = data[(time >= '2020-01-01 00:00:00') & (time <= '2020-12-31 23:00:00')]\n",
    "# fold 3\n",
    "if fold == 3:\n",
    "    train = data[(time >= '2018-01-01 00:00:00') & (time <= '2020-12-31 23:00:00')]\n",
    "    validation = data[(time >= '2021-01-01 00:00:00') & (time <= '2021-12-31 23:00:00')]\n",
    "\n",
    "\n",
    "test = data[(time >= '2022-01-01 00:00:00') & (time <= '2022-12-31 23:00:00')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f'Train shape: {train.shape}')\n",
    "print(f'Validation shape: {validation.shape}')\n",
    "print(f'Test shape: {test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features\n",
    "feature_scaler = StandardScaler()\n",
    "train_features_scaled = feature_scaler.fit_transform(train.drop(columns=['time']))\n",
    "validation_features_scaled = feature_scaler.transform(validation.drop(columns=['time']))\n",
    "test_features_scaled = feature_scaler.transform(test.drop(columns=['time']))\n",
    "\n",
    "# Normalize the target\n",
    "target_scaler = StandardScaler()\n",
    "train_target_scaled = target_scaler.fit_transform(train[['PM2.5']])\n",
    "validation_target_scaled = target_scaler.transform(validation[['PM2.5']])\n",
    "test_target_scaled = target_scaler.transform(test[['PM2.5']])\n",
    "\n",
    "# Prepare the data for LSTM\n",
    "def create_sequences(features, target, seq_length, pred_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(features) - seq_length - pred_length + 1):\n",
    "        x = features[i:i + seq_length]\n",
    "        y = target[i + seq_length:i + seq_length + pred_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "seq_length = 120\n",
    "pred_length = 12\n",
    "\n",
    "X_train, y_train = create_sequences(train_features_scaled, train_target_scaled, seq_length, pred_length)\n",
    "X_val, y_val = create_sequences(validation_features_scaled, validation_target_scaled, seq_length, pred_length)\n",
    "X_test, y_test = create_sequences(test_features_scaled, test_target_scaled, seq_length, pred_length)\n",
    "\n",
    "# Reshape for LSTM [samples, time steps, features]\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], X_val.shape[2]))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
    "\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}, y_train shape: {y_train.shape}')\n",
    "print(f'X_val shape: {X_val.shape}, y_val shape: {y_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "model = Sequential([\n",
    "    Input(shape=(seq_length, X_train.shape[2])),\n",
    "    LSTM(300, activation='softsign', return_sequences=True),\n",
    "    LSTM(300, activation='softsign', return_sequences=False),\n",
    "    Dropout(0.5),\n",
    "    Dense(pred_length, kernel_regularizer=tf.keras.regularizers.l2(0.03))\n",
    "])\n",
    "\n",
    "# Compile the model with MAE as an additional metric\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping and learning rate reduction callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, mode='min')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, min_lr=1e-10)\n",
    "\n",
    "# save running time\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# Training the Model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Making Predictions\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_val = model.predict(X_val)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "end = time.time()\n",
    "running_time = end - start\n",
    "print(f'Running time: {running_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving predictions to npy files\n",
    "np.save('y_pred_train_'+str(seq_length)+'_'+str(pred_length)+'.npy', y_pred_train)\n",
    "np.save('y_pred_val_'+str(seq_length)+'_'+str(pred_length)+'.npy', y_pred_val)\n",
    "np.save('y_pred_test_'+str(seq_length)+'_'+str(pred_length)+'.npy', y_pred_test)\n",
    "np.save('y_train_'+str(seq_length)+'_'+str(pred_length)+'.npy', y_train)\n",
    "np.save('y_val_'+str(seq_length)+'_'+str(pred_length)+'.npy', y_val)\n",
    "np.save('y_test_'+str(seq_length)+'_'+str(pred_length)+'.npy', y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
